<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.353">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Alexandre Thiéry - Sparse GP</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<link href="../../data/dice.png" rel="icon" type="image/png">
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-HJ0JLEF802"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-HJ0JLEF802', { 'anonymize_ip': true});
</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="../../styles.css">
<meta property="og:title" content="Alexandre Thiéry - Sparse GP">
<meta property="og:description" content="">
<meta property="og:site-name" content="Alexandre Thiéry">
<meta name="twitter:title" content="Alexandre Thiéry - Sparse GP">
<meta name="twitter:description" content="">
<meta name="twitter:creator" content="@alexxthiery">
<meta name="twitter:card" content="summary">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Alexandre Thiéry</span>
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../people/index_people.html" rel="" target="">
 <span class="menu-text">Research Team</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../publications/index_pubs.html" rel="" target="">
 <span class="menu-text">Publications</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../teaching/teaching.html" rel="" target="">
 <span class="menu-text">Teaching</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../notes/index_notes.html" rel="" target="">
 <span class="menu-text">Notes</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../about/about.html" rel="" target="">
 <span class="menu-text">About</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="../../notes/index_notes_as_list.xml" rel="" target=""><i class="bi bi-rss" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools">
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Sparse GP</h1>
                                <div class="quarto-categories">
                <div class="quarto-category">GP</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">18 04 2025</p>
      </div>
    </div>
    
      <div>
      <div class="quarto-title-meta-heading">Modified</div>
      <div class="quarto-title-meta-contents">
        <p class="date-modified">18 04 2025</p>
      </div>
    </div>
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#nystrom-approximation" id="toc-nystrom-approximation" class="nav-link active" data-scroll-target="#nystrom-approximation">Nystrom approximation</a></li>
  <li><a href="#observation-with-additive-gaussian-noise" id="toc-observation-with-additive-gaussian-noise" class="nav-link" data-scroll-target="#observation-with-additive-gaussian-noise">Observation with additive Gaussian noise</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">




<p><em>These notes are mainly for my own reference; I’m pretty clueless about GPs at the moment, and that needs to change. Read at your own risk; typos and mistakes are likely.</em></p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><video src="SparseGP.mp4" class="img-fluid" style="width:100.0%" controls=""><a href="SparseGP.mp4">Video</a></video></p>
</figure>
</div>
<p>Let <span class="math inline">\(f(\cdot) \sim \mathrm{GP}(m, K)\)</span> denote a Gaussian Process (GP) prior with zero mean <span class="math inline">\(m=0\)</span> and covariance kernel <span class="math inline">\(K\)</span>. Assume we observe <span class="math inline">\(n \gg 1\)</span> noisy measurements <span class="math inline">\(y = (y_i){i=1}^n\)</span> of <span class="math inline">\(f_i = f(x_i)\)</span> at input locations <span class="math inline">\(x = (x_i){i=1}^n\)</span>. The goal is to compute the posterior of <span class="math inline">\(f = (f_i)_{i=1}^n\)</span> and to infer GP hyperparameters. The main challenge with GP models is the cubic complexity of the matrix inversion required to many of the posterior computations.</p>
<p>Sparse GPs are a class of approaches that aim to reduce this complexity by approximating the full GP posterior with a smaller set of so-called inducing variables <span class="math inline">\(u=(u_1, \ldots, u_m)\)</span> that entirely describe an approximate posterior distribution. Consider <span class="math inline">\(m \ll n\)</span> locations <span class="math inline">\(z=(z_i)_{i=1}^m\)</span> called inducing points and set <span class="math inline">\(u_i = f(z_i)\)</span> for the latent function values at the inducing points. The Gaussian random variables <span class="math inline">\(u_i\)</span> can be used as inducing random variable; the choice of inducing points <span class="math inline">\(z\)</span> defines a different set of inducing variables <span class="math inline">\(u\)</span>. In this setting, optimizing the inducing variables simply means optimizing the locations of the inducing points <span class="math inline">\(z\)</span>. The strategy is to approximate the posterior of <span class="math inline">\((u,f)\)</span> with a tractable distribution <span class="math inline">\(q(u,f)\)</span>,</p>
<p><span class="math display">\[
p(u,f \mid y) \, = \, \frac{p(u) \, p(f \mid u) \, p(y \mid f)}{p(y)} \; \approx \; q(u,f).
\]</span></p>
<p>Later, we will see that setting <span class="math inline">\(u_i = f(z_i)\)</span> is indeed not the only choice of inducing variables, but let’s keep it to this for now. We have <span class="math inline">\(p(u) = N(0,K_u)\)</span> and <span class="math inline">\(p(f \mid u) = N(\mu_{f|u}, K_{f|u})\)</span> where</p>
<p><span id="eq-conditionals"><span class="math display">\[
\left\{
\begin{align*}
\mu_{f|u} &amp;= K_{fu} K_u^{-1} u\\
K_{f|u} &amp;= K_f - K_{fu} K_u^{-1} K_{uf}.
\end{align*}
\right.
\tag{1}\]</span></span></p>
<p>where <span class="math inline">\(K_u\)</span> is the covariance matrix of the inducing variables <span class="math inline">\(u\)</span> and <span class="math inline">\(K_{fu}\)</span> is the covariance matrix between <span class="math inline">\(f\)</span> and <span class="math inline">\(u\)</span>. Evaluating <span class="math inline">\(p(f \mid u)\)</span> involves inverting <span class="math inline">\(K_{f|u} \in \mathbb{R}^{n,n}\)</span>, which typically scales as <span class="math inline">\(\mathcal{O}(n^3)\)</span>, hence intractable for large <span class="math inline">\(n\)</span>. To approximate <span class="math inline">\(p(u,f \mid y)\)</span> with another distribution <span class="math inline">\(q(u,f)\)</span>, one can minimize the Kullback-Leibler divergence <span class="math inline">\(D_{\text{KL}}[q(u,f) \| p(u,f \mid y)]\)</span>, i.e.</p>
<p><span class="math display">\[
\int q(u) \, q(f|u) \, \log  {\left\{  \frac{q(u) \, q(f|u)}{p(u) \,  \textcolor{red}{p(f \mid u)} \, p(y \mid f)}  \right\}}  \, du \, df \, + \, \log p(y).
\]</span></p>
<p>It is not extremely helpful since the intractable term <span class="math inline">\( \textcolor{red}{p(f \mid u)}\)</span> is present. However, <span class="citation" data-cites="titsias2009variational">(<a href="#ref-titsias2009variational" role="doc-biblioref">Titsias 2009</a>)</span> proposes to set <span class="math inline">\(q(f|u) = p(f|u)\)</span>, i.e.&nbsp;to consider an approximate posterior of the form:</p>
<p><span class="math display">\[
q(u,f) = q(u) \, p(f \mid u).
\]</span></p>
<p>Note that the correct posterior distribution is typically not of this form, although when the number of inducing points is large enough, this approximations becomes increasingly accurate. With this class of approximate posterior, the expectation <span class="math inline">\(\mathbb{E}[\Phi(f) \mid y]\)</span> of some functional <span class="math inline">\(\Phi\)</span> is approximated as <span class="math inline">\(\int \mathbb{E}[\Phi(f) \mid u] \, q(u) \, du\)</span>. For example, if <span class="math inline">\(q(u) = \mathcal{N}(\mu_q, K_q)\)</span> is a Gaussian variational distribution, the posterior distribution of <span class="math inline">\(f_\star = f(x_\star)\)</span> at a new location <span class="math inline">\(x_\star\)</span> is approximated as <span class="math inline">\(K_{\star,u} \, K_{u}^{-1} \mathcal{N}(\mu_q, K_q) + K_{\star|u}\)</span>; it is a Gausian with</p>
<p><span class="math display">\[
\left\{
\begin{align*}
\textrm{mean} &amp;= K_{\star,u} \, K_{u}^{-1} \mu_q\\
\textrm{cov} &amp;= K_{\star,u} \, K_{u}^{-1} \, K_q \, K_{u}^{-1} K_{u,\star} + K_{\star|u}
\end{align*}
\right.
\]</span></p>
<p>Optimizing the inducing variables is equivalent to minimizing the free energy quantity</p>
<p><span id="eq-variational"><span class="math display">\[
\mathcal{F}\; \equiv \; \int q(u) \, p(f|u) \, \log  {\left\{  \frac{q(u)}{p(u) \, p(y \mid f)}  \right\}}  \, du \, df,
\tag{2}\]</span></span></p>
<p>over the variational distribution <span class="math inline">\(q(u)\)</span> and choice of inducing variables. For a fixed set of inducing variables (eg. set of inducing points), it is clear that the optimal variational distribution is given by</p>
<p><span id="eq-optimal-variational"><span class="math display">\[
\begin{align*}
q_{\star}(u)
&amp;= p(u) \exp {\left\{  \int p(f|u) \, \log  {\left( p(y \mid f) \right)}  \, df  \right\}}  / \mathcal{Z}\\
&amp;= p(u) \exp {\left\{  \mathbb{E}[\log p(y \mid f) \mid u]  \right\}}  / \mathcal{Z}
\end{align*}
\tag{3}\]</span></span></p>
<p>for some normalization constant <span class="math inline">\(\mathcal{Z}= \int p(u) \exp {\left\{  \mathbb{E}[\log p(y \mid f) \mid u]  \right\}}  \, du\)</span>; this can be seen by expressing <a href="#eq-variational">Equation&nbsp;2</a> as KL divergence, as similarly done for example when deriving the Coordinate Ascent Variational Inference (CAVI) method,</p>
<p><span id="eq-free-energy"><span class="math display">\[
\mathcal{F}= D_{\text{KL}}[q(u) \mid q_{\star}(u)] \, - \, \log \mathcal{Z}.
\tag{4}\]</span></span></p>
<p><a href="#eq-optimal-variational">Equation&nbsp;3</a> shows that <span class="math inline">\(q_{\star}(u)\)</span> is the prior <span class="math inline">\(p(u)\)</span> weighted by a term that is large when the observations <span class="math inline">\(y\)</span> are likely given <span class="math inline">\(u\)</span>, i.e.&nbsp;when <span class="math inline">\(\mathbb{E}[\log p(y \mid f) \mid u]\)</span> is large.</p>
<section id="nystrom-approximation" class="level3">
<h3 class="anchored" data-anchor-id="nystrom-approximation">Nystrom approximation</h3>
<p>Before describing the simple and most important case of additive Gaussian noise, let’s give a brief reminder on the Nystrom approximation. The distribution of <span class="math inline">\(f \mid u\)</span> is Gaussian with mean <span class="math inline">\(\mu_{f|u} = K_{fu} K_u^{-1} u\)</span> and covariance <span class="math inline">\(K_{f|u}\)</span>. This means that <span class="math inline">\(K_{fu} K_u^{-1} u + \mathcal{N}(0, K_{f|u})\)</span> is distributed as the unconditional distribution <span class="math inline">\(f \sim \mathcal{N}(0, K_f)\)</span>. In particular:</p>
<p><span class="math display">\[
\begin{align*}
K_f
&amp;= K_{fu} K_u^{-1} K_u K_u^{-1} K_{uf} + K_{f|u} \\
&amp;=  \textcolor{red}{K_{fu} K_u^{-1} K_{uf}} + K_{f|u} \\
&amp;=  \textcolor{blue}{\widehat{K}^{u}_{f}} + K_{f|u}
\end{align*}
\]</span></p>
<p>where <span class="math inline">\( \textcolor{blue}{\widehat{K}^{u}_{f}} \equiv K_{fu} K_u^{-1} K_{uf}\)</span> is the so-called <a href="https://en.wikipedia.org/wiki/Low-rank_matrix_approximations">Nystrom approximation</a> of the covariance matrix <span class="math inline">\(K_f\)</span> based on the inducing variable <span class="math inline">\(u\)</span>. This shows that the Nystrom approximation <span class="math inline">\(\widehat{K}^{u}_{f}\)</span> simply consists in ignoring the conditional variance term <span class="math inline">\(K_{f|u}\)</span>, and is thus an underestimate of the covariance matrix <span class="math inline">\(K_f\)</span>. Furthermore, if <span class="math inline">\(u\)</span> is very informative of <span class="math inline">\(f\)</span>, then <span class="math inline">\(K_{f|u}\)</span> is small and the Nystrom approximation is accurate.</p>
</section>
<section id="observation-with-additive-gaussian-noise" class="level3">
<h3 class="anchored" data-anchor-id="observation-with-additive-gaussian-noise">Observation with additive Gaussian noise</h3>
<p>The case of additive Gaussian noise is particularly simple. Assume that</p>
<p><span class="math display">\[
y_i = f_i + \varepsilon_i
\qquad \text{with} \qquad
\varepsilon_i \sim \mathcal{N}(0, \sigma^2)
\]</span></p>
<p>where the noise terms <span class="math inline">\(\varepsilon_i\)</span> are independent. Since <span class="math inline">\(f|u \sim \mathcal{N}(\mu_{f|u}, K_{f|u})\)</span>, algebra gives that</p>
<p><span class="math display">\[\mathbb{E}[\log p(y \mid f) \mid u] =
\log[ \mathcal{N}(y; \mu_{f|u}, \sigma^2 \, I) ] - \frac{1}{2 \sigma^2} \, \mathop{\mathrm{Tr}}( K_{f|u} )\]</span></p>
<p>Using that <span class="math inline">\(\mu_{f|u} = K_{fu} K_u^{-1} u\)</span> and the <a href="https://en.wikipedia.org/wiki/Woodbury_matrix_identity">matrix inversion lemma</a> it quickly follows that optimal variational distribution is <span class="math inline">\(q_{\star}(u) = \mathcal{N}(\mu_{\star}, K_{\star})\)</span> with</p>
<p><span class="math display">\[
\left\{
\begin{aligned}
\mu_{\star} &amp;= K_{uf} \,  {\left( \widehat{K}^{u}_{f} + \sigma^2 I \right)} ^{-1} \, y\\
K_{\star} &amp;= K_u - K_{uf} \,  {\left( \widehat{K}^{u}_{f} + \sigma^2 I \right)} ^{-1} \, K_{fu}.
\end{aligned}
\right.
\]</span></p>
<p>Indeed, these are approximations of the exact condition moments,</p>
<p><span class="math display">\[
\left\{
\begin{aligned}
\mu_{u|y} &amp;= K_{uf} \,  {\left( K_{f} + \sigma^2 I \right)} ^{-1} \, y\\
K_{u|y} &amp;= K_u - K_{uf} \,  {\left( K_{f} + \sigma^2 I \right)} ^{-1} \, K_{fu}.
\end{aligned}
\right.
\]</span></p>
<p>where the Nystrom approximation <span class="math inline">\(\widehat{K}^{u}_{f} \approx K_f\)</span> is used instead. One then finds that <span class="math inline">\(\log \mathcal{Z}= \log \mathcal{N}(y; 0, \widehat{K}^u_f + \sigma^2 I) - \frac{1}{2\sigma^2} \mathop{\mathrm{Tr}}(K_{f|u})\)</span>. With the optimal variational distribution <span class="math inline">\(q_\star(u)\)</span>, <a href="#eq-free-energy">Equation&nbsp;4</a> gives that the free energy is:</p>
<p><span class="math display">\[
\mathcal{F}
= -\log \mathcal{N} {\left( y; 0, \; \widehat{K}^{u}_{f} + \sigma^2 I \right)}  + \frac{1}{2\sigma^2} \mathop{\mathrm{Tr}}K_{f|u} \\
\]</span></p>
<p>Furthermore, note that exact likelihood of the observations is <span class="math inline">\(p(y) = \mathcal{N} {\left( y; 0, \; K_f + \sigma^2 I \right)} \)</span> so that the free energy can be expressed as</p>
<p><span class="math display">\[
\mathcal{F}
\; = \;
-\log \widehat{p}^u(y) + \frac{1}{2\sigma^2} \mathop{\mathrm{Tr}}K_{f|u} \\
\]</span></p>
<p>for pseudo-likelihood <span class="math inline">\(\widehat{p}^u(y) = \mathcal{N} {\left( y; 0, \; \widehat{K}^{u}_{f} + \sigma^2 I \right)} \)</span>. This shows that <span class="math inline">\(D_{\text{KL}}\)</span> is given by: <span class="math display">\[
\begin{align*}
D_{\text{KL}}&amp;[q(u,f) \mid p(u,f \mid y)]
=
\mathcal{F}+ \log p(y) \\
&amp;=
\log \frac{p(y)}{\widehat{p}^u(y)}
+
\frac{1}{2\sigma^2} \mathop{\mathrm{Tr}}K_{f|u}.
\end{align*}
\]</span></p>
<p>The term <span class="math inline">\(\mathop{\mathrm{Tr}}K_{f|u}\)</span> is just the sum of the conditional variances <span class="math inline">\(\mathop{\mathrm{Var}} {\left( f_i | u \right)} \)</span> and can be thought of as a regularization term,</p>
<p><span class="math display">\[
R = \frac{1}{2\sigma^2} \mathop{\mathrm{Tr}}K_{f|u} =
\frac12 \, \sum_{i=1}^n \frac{\mathop{\mathrm{Var}} {\left( f_i | u \right)} }{\sigma^2}.
\]</span></p>
<p>As the number of inducing variables <span class="math inline">\(m\)</span> increases, the pseudo-likelihood becomes more accurate <span class="math inline">\(\widehat{p}^u(y) \to p(y)\)</span>, the conditional variances <span class="math inline">\(\mathop{\mathrm{Var}} {\left( f_i | u \right)}  \to 0\)</span> shrink to zero, and the KL divergence <span class="math inline">\(D_{\text{KL}}[q(u,f) \mid p(u,f \mid y)]\)</span> approaches zero.</p>
<p>The animation at the start of this note illustrates the effect of optimizing the location of the inducing points <span class="math inline">\(z\)</span> with a very simple gradient descent. A few experiments show that it is worth being careful with the initial choice of inducing points. Inducing points chosen very far from the data essentially remain fixed during the optimization (ie. the gradient is very small). Initializing with <a href="https://en.wikipedia.org/wiki/K-means%2B%2B">k-means++</a> clustering of the data points seems to be a robust strategy and give an almost optimal choice of inducing points.</p>



</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" role="list">
<div id="ref-titsias2009variational" class="csl-entry" role="listitem">
Titsias, Michalis. 2009. <span>“Variational Learning of Inducing Variables in Sparse Gaussian Processes.”</span> In <em>Artificial Intelligence and Statistics</em>, 567–74. PMLR.
</div>
</div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<script src="https://utteranc.es/client.js" repo="alexxthiery/blogComments" issue-term="pathname" theme="github-light" crossorigin="anonymous" async="">
</script>
</div> <!-- /content -->



</body></html>