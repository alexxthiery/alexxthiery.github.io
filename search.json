[
  {
    "objectID": "posts/reverse_and_tweedie/reverse_and_tweedie.html",
    "href": "posts/reverse_and_tweedie/reverse_and_tweedie.html",
    "title": "Reverse diffusions, Score & Tweedie",
    "section": "",
    "text": "Video\n\n\nImagine a scalar diffusion process \\(\\{X_t\\}_{t=0}^T\\) defined on the interval \\([0,T]\\),\n\\[dX = \\mu(X) \\, dt + \\sigma \\, dW\\]\nwhere \\(\\mu(X)\\) is the drift term, \\(\\sigma\\) is the diffusion coefficient, and \\(dW\\) is a Wiener process. Denote the distribution of this process at time \\(t\\) (\\(0 \\leq t \\leq T\\)) as \\(p_t(dx)\\) with an initial distribution of \\(p_0(dx)\\). Now, what happens if we reverse time and examine the process backward? In other words, consider the time-reversed process \\(\\overleftarrow{X}\\) defined as\n\\[\\overleftarrow{X}_s = X_{T-s}.\\]\nIntuitively, the process \\(\\overleftarrow{X}\\) is also a diffusion on the interval \\([0, T]\\), but with an initial distribution \\(\\overleftarrow{X}_0 \\sim p_T(dx)\\). To gain intuition, consider an Euler discretization of the forward process:\n\\[X_{t+\\delta} = X_{t} + \\mu(X_t)\\, \\delta + \\sigma \\, \\sqrt{\\delta} \\, \\mathbf{n} \\tag{1}\\]\nwhere \\(\\mathbf{n}\\sim \\mathcal{N}(0,1)\\) represents a noise term independent from \\(X_{t}\\), and \\(\\delta \\ll 1\\) is a time increment. Re-arranging terms and making the approximation \\(\\mu(X_t) \\approx \\mu(X_{t+\\delta})\\) gives that\n\\[X_{t} \\approx X_{t+\\delta} - \\mu(X_{t+\\delta})\\, \\delta + \\sigma \\, \\sqrt{\\delta} \\, (-\\mathbf{n}). \\tag{2}\\]\nThis seems to suggest that the time-reversed process follows the dynamics \\(d\\overleftarrow{X} = -\\mu(\\overleftarrow{X}) \\, dt + \\sigma \\, dW\\) started from \\(\\overleftarrow{X}_0 \\sim p_T(dx)\\). However, this conclusion is incorrect because this would suggest that the time-reversed of a standard Brownian motion (where \\(\\mu(x) \\equiv 0\\)) starting at zero is also a Brownian motion starting at \\(p_T(dx) = \\mathcal{N}(0,T)\\), which is clearly not the case. The flaw in this argument lies in assuming that the noise term \\(Z\\) is independent of \\(X_{t+\\delta}\\), which is not true, rendering the Euler discretization argument invalid.\nDeriving the dynamics of the backward process in a rigorous manner is not straightforward (Anderson 1982) (Haussmann and Pardoux 1986). What follows is a heuristic derivation that proceeds by estimating the mean and variance of \\(X_{t}\\) given \\(X_{t+\\delta} = x_{t+\\delta}\\), assuming \\(\\delta \\ll 1\\). Here, \\(x_{t+\\delta}\\) is treated as a fixed and constant value, and we are only interested in the conditional distribution of \\(X_t\\) given \\(x_{t+\\delta}\\). Bayes’ law gives\n\\[\\mathbb{P}(X_t \\in dx | x_{t+\\delta}) \\propto p_t(x) \\, \\exp\\left\\{ -\\frac{\\left( x_{t+\\delta} - [x + \\mu(x) \\, \\delta] \\right)^2}{2 \\sigma^2 \\, \\delta} \\right\\},\\]\nwhere the exponential term corresponds to the transition of the forward diffusion for \\(\\delta \\ll 1\\). Using the 1st order approximation\n\\[p_t(x) \\approx p_t(x_{t+\\delta}) \\,\\exp\\left( \\langle \\nabla \\log p_t(x_{t+\\delta}), (x-x_{t+\\delta})\\rangle\\right),\\]\neliminating multiplicative constants and higher-order error terms, we obtain:\n\\[\\mathbb{P}(X_t \\in dx | x_{t+\\delta})\n\\propto\n\\exp\\left\\{ -\\frac{\\left( x - [x_{t+\\delta} - \\mu(x_{t+\\delta}) \\delta\n+ {\\color{red} \\sigma^2 \\, \\nabla \\log p_t(x_{t+\\delta}) \\, \\delta} ] \\right)^2}{2 \\sigma^2 \\, \\delta} \\right\\}.\\]\nFor \\(\\delta \\ll 1\\), this is transition of the reverse diffusion\n\\[\nd\\overleftarrow{X}_t = -\\mu(\\overleftarrow{X}_t) \\, dt \\; + {\\color{red} \\sigma^2 \\, \\nabla \\log p_{T-t}(\\overleftarrow{X}_t) \\, dt} \\; + \\; \\sigma \\, dB.\n\\]\nThe notation \\(B\\) is used to emphasize that this Brownian motion is distinct from the one used in the forward diffusion. The additional drift term, denoted as \\({\\color{red} \\sigma^2 \\, \\nabla \\log p_t(\\overleftarrow{X})}\\), is intuitive: it pushes the reverse diffusion toward regions where the forward diffusion spent a significant amount of time, i.e., where \\(p_t(dx)\\) is large. The popular “denoising diffusion models” (Ho, Jain, and Abbeel 2020) can be seen as discretizations of this backward process, employing various techniques to estimate the additional drift term from data."
  },
  {
    "objectID": "posts/reverse_and_tweedie/reverse_and_tweedie.html#reversing-a-diffusion",
    "href": "posts/reverse_and_tweedie/reverse_and_tweedie.html#reversing-a-diffusion",
    "title": "Reverse diffusions, Score & Tweedie",
    "section": "",
    "text": "Video\n\n\nImagine a scalar diffusion process \\(\\{X_t\\}_{t=0}^T\\) defined on the interval \\([0,T]\\),\n\\[dX = \\mu(X) \\, dt + \\sigma \\, dW\\]\nwhere \\(\\mu(X)\\) is the drift term, \\(\\sigma\\) is the diffusion coefficient, and \\(dW\\) is a Wiener process. Denote the distribution of this process at time \\(t\\) (\\(0 \\leq t \\leq T\\)) as \\(p_t(dx)\\) with an initial distribution of \\(p_0(dx)\\). Now, what happens if we reverse time and examine the process backward? In other words, consider the time-reversed process \\(\\overleftarrow{X}\\) defined as\n\\[\\overleftarrow{X}_s = X_{T-s}.\\]\nIntuitively, the process \\(\\overleftarrow{X}\\) is also a diffusion on the interval \\([0, T]\\), but with an initial distribution \\(\\overleftarrow{X}_0 \\sim p_T(dx)\\). To gain intuition, consider an Euler discretization of the forward process:\n\\[X_{t+\\delta} = X_{t} + \\mu(X_t)\\, \\delta + \\sigma \\, \\sqrt{\\delta} \\, \\mathbf{n} \\tag{1}\\]\nwhere \\(\\mathbf{n}\\sim \\mathcal{N}(0,1)\\) represents a noise term independent from \\(X_{t}\\), and \\(\\delta \\ll 1\\) is a time increment. Re-arranging terms and making the approximation \\(\\mu(X_t) \\approx \\mu(X_{t+\\delta})\\) gives that\n\\[X_{t} \\approx X_{t+\\delta} - \\mu(X_{t+\\delta})\\, \\delta + \\sigma \\, \\sqrt{\\delta} \\, (-\\mathbf{n}). \\tag{2}\\]\nThis seems to suggest that the time-reversed process follows the dynamics \\(d\\overleftarrow{X} = -\\mu(\\overleftarrow{X}) \\, dt + \\sigma \\, dW\\) started from \\(\\overleftarrow{X}_0 \\sim p_T(dx)\\). However, this conclusion is incorrect because this would suggest that the time-reversed of a standard Brownian motion (where \\(\\mu(x) \\equiv 0\\)) starting at zero is also a Brownian motion starting at \\(p_T(dx) = \\mathcal{N}(0,T)\\), which is clearly not the case. The flaw in this argument lies in assuming that the noise term \\(Z\\) is independent of \\(X_{t+\\delta}\\), which is not true, rendering the Euler discretization argument invalid.\nDeriving the dynamics of the backward process in a rigorous manner is not straightforward (Anderson 1982) (Haussmann and Pardoux 1986). What follows is a heuristic derivation that proceeds by estimating the mean and variance of \\(X_{t}\\) given \\(X_{t+\\delta} = x_{t+\\delta}\\), assuming \\(\\delta \\ll 1\\). Here, \\(x_{t+\\delta}\\) is treated as a fixed and constant value, and we are only interested in the conditional distribution of \\(X_t\\) given \\(x_{t+\\delta}\\). Bayes’ law gives\n\\[\\mathbb{P}(X_t \\in dx | x_{t+\\delta}) \\propto p_t(x) \\, \\exp\\left\\{ -\\frac{\\left( x_{t+\\delta} - [x + \\mu(x) \\, \\delta] \\right)^2}{2 \\sigma^2 \\, \\delta} \\right\\},\\]\nwhere the exponential term corresponds to the transition of the forward diffusion for \\(\\delta \\ll 1\\). Using the 1st order approximation\n\\[p_t(x) \\approx p_t(x_{t+\\delta}) \\,\\exp\\left( \\langle \\nabla \\log p_t(x_{t+\\delta}), (x-x_{t+\\delta})\\rangle\\right),\\]\neliminating multiplicative constants and higher-order error terms, we obtain:\n\\[\\mathbb{P}(X_t \\in dx | x_{t+\\delta})\n\\propto\n\\exp\\left\\{ -\\frac{\\left( x - [x_{t+\\delta} - \\mu(x_{t+\\delta}) \\delta\n+ {\\color{red} \\sigma^2 \\, \\nabla \\log p_t(x_{t+\\delta}) \\, \\delta} ] \\right)^2}{2 \\sigma^2 \\, \\delta} \\right\\}.\\]\nFor \\(\\delta \\ll 1\\), this is transition of the reverse diffusion\n\\[\nd\\overleftarrow{X}_t = -\\mu(\\overleftarrow{X}_t) \\, dt \\; + {\\color{red} \\sigma^2 \\, \\nabla \\log p_{T-t}(\\overleftarrow{X}_t) \\, dt} \\; + \\; \\sigma \\, dB.\n\\]\nThe notation \\(B\\) is used to emphasize that this Brownian motion is distinct from the one used in the forward diffusion. The additional drift term, denoted as \\({\\color{red} \\sigma^2 \\, \\nabla \\log p_t(\\overleftarrow{X})}\\), is intuitive: it pushes the reverse diffusion toward regions where the forward diffusion spent a significant amount of time, i.e., where \\(p_t(dx)\\) is large. The popular “denoising diffusion models” (Ho, Jain, and Abbeel 2020) can be seen as discretizations of this backward process, employing various techniques to estimate the additional drift term from data."
  },
  {
    "objectID": "posts/reverse_and_tweedie/reverse_and_tweedie.html#denoising-score-matching-tweedie-formula",
    "href": "posts/reverse_and_tweedie/reverse_and_tweedie.html#denoising-score-matching-tweedie-formula",
    "title": "Reverse diffusions, Score & Tweedie",
    "section": "Denoising Score Matching & Tweedie formula",
    "text": "Denoising Score Matching & Tweedie formula\n\n\n\n\nMaurice Tweedie (1919–1996)\n\n\n\nThe previous section shows that a quantity often referred to as the “score” in machine learning (ML) literature, i.e. \\(\\mathcal{S}_t(x) \\equiv \\nabla_x \\log p_t(x)\\), naturally arises when a diffusion process runs backward in time. Interestingly, it is worth noting that since the beginning of times statisticians have been using the term “score” to refer to the other derivative, i.e. the derivative with respect to a model’s parameter, which is a completely different object!\nConsider a Brownian diffusion process \\(dX = \\sigma \\, dW\\) initiated from a distribution \\(\\mu(dx) = p_0(dx)\\). If this process is ran forward for a duration \\(\\delta&gt;0\\), we have:\n\\[X_{\\delta} = X_0 + \\mathcal{N}(0, \\sigma^2 \\, \\delta)\\]\nwhere \\(X_0 \\sim \\mu(dx)\\). Now, focusing on a specific sample \\(y = X_{\\delta}\\), the backward dynamics \\(d\\overleftarrow{X} = \\sigma^2 \\, \\nabla \\log p_t(\\overleftarrow{X}) , dt + \\sigma \\, dB\\) suggests that for sufficiently small \\(\\delta\\), the following approximation holds:\n\\[\n\\mathbb{E}[X_0 \\, | X_{\\delta} = y] \\; { \\color{\\red} \\approx} \\; y + \\nabla \\log p_{\\delta}(y) \\, \\sigma^2 \\delta.\n\\tag{3}\\]\nMaybe surprisingly, in the case of Brownian dynamics (no drift), this relationship holds exactly, even for arbitrarily large time increments \\(\\delta&gt;0\\). This observation attributed in (Efron 2011) to Maurice Tweedie (1919–1996) has a straightforward proof. Specifically, if \\(X \\sim \\mu(dx)\\), then \\(Y = X + \\mathcal{N}(0, \\Gamma^2)\\) has a density given by:\n\\[\np_Y(dy) = \\int \\mu(x) \\, \\rho_{\\Gamma}(y-x) \\, dx\n\\]\nwhere \\(\\rho_{\\Gamma}(z) \\propto \\exp[-z^2/(2 \\Gamma^2)]\\) is a centred Gaussian with variance \\(\\Gamma^2\\). It follows that\n\\[\n\\frac{ \\mathbb{E}[X \\, | Y = y]-y}{\\Gamma^2} = \\frac{ \\int \\left( \\frac {x-y }{\\Gamma^2} \\right)\\, \\mu(x) \\, \\rho_{\\Gamma}(y-x) \\, dx }{\\int \\mu(x) \\, \\rho_{\\Gamma}(y-x) \\, dx}\n=\n\\nabla_y \\log \\left\\{ \\int \\mu(x) \\, \\rho_{\\Gamma}(y-x) \\, dx \\right\\}\n\\]\nsince \\(\\nabla_y \\rho_{\\Gamma}(y-x) = (x-y)/\\Gamma^2\\). This leads to Tweedie’s formula:\n\\[\n\\mathbb{E}[X \\, | Y = y] \\; {\\color{red} =} \\; y + \\Gamma^2 \\, \\nabla \\log p_Y(y),\n\\]\nwhich is exactly the same as Equation 3 but with an equality sign: no approximation needed! Interestingly, this is what Machine-Learners often refer to as “denoising score matching” (Vincent 2011): if we have access to a large number of samples \\((X_i,Y_i)\\), where \\(X_i \\sim \\mu(dx)\\) and \\(Y_i = X_i + \\mathcal{N}(0, \\Gamma^2)\\), and fit a regression model \\(F_{\\theta}\\) by minimizing the mean-squared error \\(\\theta \\mapsto \\mathbb{E} \\|X - F_{\\theta}(Y)\\|^2\\), then Tweedie formula shows that in the limit of infinite samples and with sufficient flexibility in the regression model \\(F_{\\theta_\\star}(y) = y + \\Gamma^2 \\nabla \\log p_Y(y)\\). This allows one to estimate \\(\\nabla \\log p_Y\\) from data, which is often a good approximation of \\(\\nabla \\log \\mu\\) if the variance \\(\\Gamma^2\\) of the added noise is not too large. Indeed, things can go bad if \\(\\Gamma^2\\) is very small and the number of training data is not large, no free lunch!"
  },
  {
    "objectID": "posts/hello_world/index.html",
    "href": "posts/hello_world/index.html",
    "title": "Hello World",
    "section": "",
    "text": "Just testing whether Latex is working correctly: \\[\\frac{1}{2}\\left( \\int \\exp\\left\\{ -\\frac{x^2}{2}\\right\\} \\, dx \\right)^2 \\approx 22/7\\]\nHere is a reference (MacKay 2003) and below is an animation:\n\n\nVideo\n\n\n\n\n\n\nReferences\n\nMacKay, David JC. 2003. Information Theory, Inference and Learning Algorithms. Cambridge university press."
  },
  {
    "objectID": "posts/index_blog.html",
    "href": "posts/index_blog.html",
    "title": "Alexandre Thiéry",
    "section": "",
    "text": "Blogposts (vaguely) related to research, notes for students, announcements, things I would like to write down to understand better and/or not forget, etc… Comments, corrections, suggestions are welcome!\n\n\n\n\n\n\n\n\n\n\nDate\n\n\nTitle\n\n\nCategories\n\n\n\n\n\n\n12-06-2023\n\n\nReverse diffusions, Score & Tweedie\n\n\nSDE,Generative-Model\n\n\n\n\n06-06-2023\n\n\nHello World\n\n\ntesting\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "publications/index_pubs.html#theory-methods",
    "href": "publications/index_pubs.html#theory-methods",
    "title": "Alexandre Thiéry",
    "section": "THEORY & METHODS:",
    "text": "THEORY & METHODS:\n\n\n\n Computational Doob’s H-transforms for Online Filtering of Discretely Observed Diffusions   Nicolas Chopin, Andras Fulop, Jeremy Heng, Alexandre H. Thiery, (2023)   International Conference on Machine Learning (ICML) 2023    (Arxiv) \n\n\n Conditional sequential Monte Carlo in high dimensions   Axel Finke and Alexandre H. Thiery, (2023)   Annals of Statistics 2023, In Press    (Arxiv)   (Journal)  \n\n\n Pretrained equivariant features improve unsupervised landmark discovery   Rahul Rahaman, Atin Ghosh and Alexandre H. Thiery, (2022)   International Conference of Pattern Recognition (ICPR) 2022    (Arxiv) \n\n\n Manifold lifting: scaling MCMC to the vanishing noise regime   Khai Xiang Au, Matthew Graham, Alexandre H. Thiery, (2022)   JRSSB 2022    (Arxiv)   (Journal)  \n\n\n A discrete Bouncy Particle Sampler   Chris Sherlock and Alexandre H. Thiery, (2022)   Biometrika, Volume 109, Issue 2 (2022)    (Arxiv)   (Journal)  \n\n\n A Generalized & Robust Framework For Timestamp Supervision in Temporal Action Segmentation   Rahul Rahaman, Dipika Singhania, Alexandre H. Thiery, Angela Yao, (2022)   European Conference on Computer Vision (ECCV) 2022    (Journal)  \n\n\n Manifold Markov chain Monte Carlo methods for Bayesian inference in a wide class of diffusion models   Matthew Graham, Alexandre H. Thiery, Alex Beskos, (2022)   JRSSB, Volume 84 (4), 2022    (Arxiv)   (Journal)  \n\n\n Sequential Ensemble Transform for Bayesian Inverse Problems   Aaron Myers, Alexandre H. Thiery, Kainan Wang and Tan Bui-Tanh, (2021)   Journal of Computational Physics, Volume 427 (2021)    (Arxiv)   (Journal)  \n\n\n On Data-Augmentation and Consistency-Based Semi-Supervised Learning   Atin Ghosh and Alexandre H. Thiery, (2021)   ICLR 2021    (Arxiv) \n\n\n Uncertainty Quantification and Deep Ensembles   Rahul Rahaman and Alexandre H. Thiery, (2021)   NeuRIPS 2021    (Arxiv) \n\n\n On importance-weighted autoencoders   Axel Finke and Alexandre H. Thiery, (2019)   Tech Report    (Arxiv) \n\n\n A scalable optimal-transport based local particle filter   Matthew Graham and Alexandre H. Thiery, (2019)   Tech Report    (Arxiv) \n\n\n Particle Filter efficiency under limited communication   Deborshee Sen and Alexandre H. Thiery, (2019)   Tech Report    (Arxiv) \n\n\n Error Bounds for Sequential Monte Carlo Samplers for Multimodal Distributions   Daniel Paulin, Ajay Jasra and Alexandre H. Thiery, (2019)   Bernoulli, Volume 25, Number 1 (2019)    (Arxiv)   (Journal)  \n\n\n Asymptotic Analysis of the Random-Walk Metropolis Algorithm on Ridged Densities   Alex Beskos, Gareth Roberts, Alexandre H. Thiery and Natesh Pillai, (2018)   Annals of Applied Probability, Volume 28, Number 5 (2018)    (Arxiv)   (Journal)  \n\n\n On Coupling Particle Filter Trajectories   Deborshee Sen, Alexandre H. Thiery, Ajay Jasra, (2018)   Statistics and Computing, Volume 28, Number 2 (2018)    (Arxiv)   (Journal)  \n\n\n Levy statistics of interacting Rydberg gases   Thibault Vogt, Jingshan Han, Alexandre H. Thiery, Wenhui Li, (2017)   Physical Review A, Volume 95, Number 5 (2017)    (Arxiv)   (Journal)  \n\n\n Pseudo-marginal Metropolis–Hastings using averages of unbiased estimators   Chris Sherlock, Alexandre H. Thiery and Anthony Lee, (2017)   Biometrika, Volume 104, Number 3 (2017)    (Arxiv)   (Journal)  \n\n\n On the Convergence of Adaptive Sequential Monte Carlo Methods   Alex Beskos, Ajay Jasra, Nikolas Kantas, Alexandre H. Thiery, (2016)   Annals of Applied Probability, Volume 26, Number 2 (2016)    (Arxiv)   (Journal)  \n\n\n Consistency and fluctuations for stochastic gradient Langevin dynamics   Yee Whye Teh, Alexandre H. Thiery, Sebastian Vollmer, (2016)   Journal of Machine Learning Research, Volume 17 (2016)    (Arxiv)   (Journal)  \n\n\n On the efficiency of pseudo-marginal random walk Metropolis algorithms   Chris Sherlock, Alexandre H. Thiery, Gareth Roberts, Jeff Rosenthal, (2015)   Annals of Statistics, Volume 43, Number 1 (2015)    (Arxiv)   (Journal)  \n\n\n On non-negative unbiased estimators   Pierre Jacob, Alexandre H. Thiery, (2015)   Annals of Statistics, Volume 43, Number 2 (2015)    (Arxiv)   (Journal)  \n\n\n Efficiency of delayed-acceptance random walk Metropolis algorithms   Chris Sherlock, Alexandre H. Thiery and Andrew Golightly, (2015)   Annals of Statistics (In Press)    (Arxiv)   (Journal)  \n\n\n Noisy gradient flow from a random walk in Hilbert space   Natesh Pillai, Andrew Stuart, Alexandre H. Thiery, (2014)   Stochastic Partial Differential Equations: Analysis and Computations, Volume 2, Number 2 (2014)    (Arxiv)   (Journal)  \n\n\n Optimal Scaling and Diffusion Limits for the Langevin Algorithm in High Dimensions   Natesh Pillai, Andrew Stuart, Alexandre H. Thiery, (2012)   Annals of Applied Probability, Volume 22, Number 6 (2012)    (Arxiv)   (Journal)  \n\n\n\nNo matching items"
  },
  {
    "objectID": "publications/index_pubs.html#applications",
    "href": "publications/index_pubs.html#applications",
    "title": "Alexandre Thiéry",
    "section": "APPLICATIONS",
    "text": "APPLICATIONS\n\n\n\n Three-Dimensional Structural Phenotype of the Optic Nerve Head as a Function of Glaucoma Severity   Braeu, F.A., Chuangsuwanich, T., Tun, T.A., Perera, S.A., Husain, R., Kadziauskienė, A., Schmetterer, L., Thiéry, A.H., Barbastathis, G., Aung, T. and Girard, M.J.A., (2023)   JAMA Ophthalmology, 2023    (Arxiv)   (Journal)  \n\n\n Towards Label-Free 3D Segmentation of Optical Coherence Tomography Images of the Optic Nerve Head Using Deep Learning   Devalla,S.K., Pham, T.H., Panda, S.K, Zhang,L., Subramanian,G., Swaminathan,A., Chin,Z.Y, Rajan,M., Mohan,S., Krishnadas,R., Senthil,V., Leon,J.M, Tun,T.A., Cheng,C.Y., Schmetterer, L., Perera,S., Aung,T., Thiery,A.H., Girard,M.J.A., (2023)   Biomedical Optics Express, Vol. 11, Issue 11    (Arxiv)   (Journal)  \n\n\n Geometric Deep Learning to Identify the Critical 3D Structural Features of the Optic Nerve Head for Glaucoma Diagnosis   Braeu, F., Thiery, A.H, Tun, T.A., Kadziauskiene, A., Barbastathis, G., Aung, T., and Girard. M.J.A., (2023)   American Journal of Ophthalmology, 2023    (Arxiv)   (Journal)  \n\n\n Medical Application of Geometric Deep Learning for the Diagnosis of Glaucoma   Thiery, A.H, Braeu, F., Tun, T.A., Aung, T., Girard. M.J.A., (2023)   Translational Vision Science and Technology, 2023    (Arxiv)   (Journal)  \n\n\n Detection of m6A from direct RNA sequencing using a Multiple Instance Learning framework   Hendra C, Pratanwanich PN, Wan YK, Goh WS, Thiery A, Göke J+., (2022)   Nature Methods (2022)    (Arxiv)   (Journal)  \n\n\n Describing the Structural Phenotype of the Glaucomatous Optic Nerve Head Using Artificial Intelligence   Panda, S.K., Cheong, H., Tun,T.A., Devella, S.K., Krishnadas, R., Buist, M.L., Perera, S., Cheng, C-Y., Aung, T., Thiery A.H., Girard, M.J.A., (2022)   American Journal of Ophthalmology, 2022    (Arxiv)   (Journal)  \n\n\n The Three-Dimensional Structural Configuration of the Central Retinal Vessel Trunk and Branches as a Glaucoma Biomarker   Satish K Panda, Haris Cheong, Tin A Tun, Thanadet Chuangsuwanich, Aiste Kadziauskiene, Vijayalakshmi Senthil, Ramaswami Krishnadas, Martin L Buist, Shamira Perera, Ching-Yu Cheng, Tin Aung, Alexandre H Thiery, Michaël JA Girard, (2022)   American Journal of Ophthalmology, 2022    (Journal)  \n\n\n Deep Learning Algorithms to Isolate and Quantify the Structures of the Anterior Segment in Optical Coherence Tomography Images   Pham, T.H, Devalla,S.K., Ang, A., Da,S.Z., Thiery,A.H., Boote,C., Cheng,C.Y., Koh,V., Girard, M.J.A., (2021)   British Journal of Ophthalmology    (Arxiv)   (Journal)  \n\n\n Identification of differential RNA modifications from nanopore direct RNA sequencing with xPore   Ploy N. Pratanwanich, Fei Yao, Ying Chen, Casslynn W.Q. Koh, Christopher Hendra, Polly Poon, Yeek Teck Goh, Phoebe M. L. Yap, Choi Jing Yuan, Wee Joo Chng, Sarah Ng, Alexandre Thiery, W.S. Sho Goh, Jonathan Goeke, (2021)   Nature Biotechnology, 2021    (Arxiv)   (Journal)  \n\n\n Beyond quadratic error: Case-study of a multiple criteria approach to the performance assessment of numerical forecasts of solar irradiance in the tropics   Verbois, H., Blanc, P., Huva, R., Saint-Drenan, Y-M, Rusydi, A.. Thiery, A., (2020)   Renewable and Sustainable Energy Reviews, Volume 117, (2020)    (Journal)  \n\n\n NanoVar: Accurate Characterization of Patients Genomic Structural Variants Using Low-Depth Nanopore Sequencing   Tham, C.Y, Tirado-Magallanes, R., Goh, Y., Fullwood, M. J., Koh, B.T.H. , Wang, W., Ng, C.H, Chng, W.J., Thiery, A.H., Tenen, D.G, Benoukraf, (2020)   Genome Biology (2020)    (Arxiv)   (Journal)  \n\n\n DeshadowGAN: A Deep Learning Approach to Remove Shadows from Optical Coherence Tomography Images   Cheong, H., Devalla, S.K., Pham, T.H., Liang, Z., Tun, T.A., Wang, X., Perera, S., Schmetterer, L., Tin, A., Boote, C., Thiery, A.H., Girard, M.J.A., (2020)   Translational Vision Science & Technology    (Arxiv)   (Journal)  \n\n\n Deep Learning Algorithms to Isolate and Quantify the Structures of the Anterior Segment in Optical Coherence Tomography Images   Pham, T.H, Devalla,S.K., Ang, A., Da, S.Z., Thiery, A.H., Boote,C., Cheng,C.Y., Koh,V., Girard, M.J.A, (2020)   British Journal of Ophthalmology, 2020    (Arxiv)   (Journal)  \n\n\n A Deep Learning Approach to Denoise Optical Coherence Tomography Images of the Optic Nerve Head   Devalla SK, Subramanian G, Pham TH, Wang X, Perera S, Tun TA, Aung T, Schmetterer L, Thiery A.H., Girard MJA, (2019)   Scientific Reports (2019)    (Arxiv)   (Journal)  \n\n\n Glaucoma management in the era of artificial intelligence   Devalla S.K., Liang Z., Pham T.H., Boote, C., Strouthidis, N.G., Thiery A.H., Girard M.J.A., (2019)   British Journal of Ophthalmology (2019)    (Journal)  \n\n\n DRUNET: A Dilated-Residual U-Net Deep Learning Network to Digitally Stain Optic Nerve Head Tissues in Optical Coherence Tomography Images   Devalla SK, Renukanand PK, Sreedhar BK, Perera SA, Mari JM, Chin KS, Tun TA, Strouthidis N, Aung T, Thiery A.H., Girard MJA, (2018)   Biomedical Optics Express, Vol. 9, Issue 7 (2018)    (Arxiv)   (Journal)  \n\n\n Probabilistic forecasting of day-ahead solar irradiance using quantile gradient boosting   Verbois, H., Rusydi, A., Thiery, A.H., (2018)   Solar Energy 173, 313-327 (2018)    (Journal)  \n\n\n\nNo matching items"
  },
  {
    "objectID": "about/about.html",
    "href": "about/about.html",
    "title": "Alexandre Thiéry",
    "section": "",
    "text": "Email: a.h.thiery [at] nus.edu.sg\nOffice: Building S16, Office #06-113"
  },
  {
    "objectID": "about/about.html#address",
    "href": "about/about.html#address",
    "title": "Alexandre Thiéry",
    "section": "",
    "text": "Email: a.h.thiery [at] nus.edu.sg\nOffice: Building S16, Office #06-113"
  },
  {
    "objectID": "about/about.html#qualifications",
    "href": "about/about.html#qualifications",
    "title": "Alexandre Thiéry",
    "section": "Qualifications",
    "text": "Qualifications\n\nPh.D., Probability & Statistics, Warwick University, 2009-2013.\nEcole Normale Superieure of Paris, Mathematics, 2005-2009\n\nResearch Assistant, Statslab (Cambridge, UK)\nMSc (Probability & Finance), University of Paris VI\nMSc (Partial Differential Equations & Modeling), University of Paris VI"
  },
  {
    "objectID": "about/about.html#employment-history",
    "href": "about/about.html#employment-history",
    "title": "Alexandre Thiéry",
    "section": "Employment history",
    "text": "Employment history\n\nAssociate Professor, Department of Statistics & Data Sciences, NUS, 2020–present.\nAffiliate, NUS Centre for Data Science and Machine Learning, 2021–present\nAffiliate, NUS Institute of Data Science, 2028–present\nAffiliate, NUS Graduate School for Integrative Sciences and Engineering, 2017–present\nAssistant Professor, Department of Statistics & Probability, NUS, 2014–2019.\nResearch Fellow, Department of Statistics & Probability, NUS, 2013"
  },
  {
    "objectID": "about/about.html#leadership",
    "href": "about/about.html#leadership",
    "title": "Alexandre Thiéry",
    "section": "Leadership",
    "text": "Leadership\n\nDeputy Director of the Institute for Mathematical Sciences (IMS), 2020–2023"
  },
  {
    "objectID": "about/about.html#service",
    "href": "about/about.html#service",
    "title": "Alexandre Thiéry",
    "section": "Service",
    "text": "Service\n\nArea Chair for AISTAT (2023), NeurIPS (2023), ACML (2023)\nAssociate Editor for Statistics & Computing (2020–2022)"
  },
  {
    "objectID": "about/about.html#awards-and-honours",
    "href": "about/about.html#awards-and-honours",
    "title": "Alexandre Thiéry",
    "section": "Awards and honours",
    "text": "Awards and honours\n\nNUS Faculty of Sciences Dean’s Chair Associate Professor, 2022–2025\nNUS Faculty Teaching Excellence Award, 2022\nNUS Faculty Teaching Excellence Award, 2019\nNUS Faculty Teaching Excellence Award, 2018\nNUS Young Scientist Award. (Faculty of Science: 1 awardee per year), 2017\nNUS Young Investigator Award. (Faculty of Science: 3 awardees per year), 2016\nJohn Copas prize for the best PhD dissertation, 2013"
  },
  {
    "objectID": "about/about.html#industrial-activities",
    "href": "about/about.html#industrial-activities",
    "title": "Alexandre Thiéry",
    "section": "Industrial Activities",
    "text": "Industrial Activities\n\nCo-founder of Abyss Processing, start-up developing AI solutions for ophthalmology\nConsulting in the finance and health-care industries"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Alexandre Thiéry",
    "section": "",
    "text": "Google-Scholar\n  \n  \n    \n     Arxiv\n  \n  \n    \n     twitter\n  \n\n      \nAssociate Professor\nDepartment of Statistics & Data Science\nNational University of Singapore\n\n\n\nComputational Statistics & Machine Learning\nMonte-Carlo methods\nUncertainty Quantification\nInverse problems\n\n\n\n\nOffice: Building S16, Office #06-113\nEmail: a.h.thiery [at] nus.edu.sg"
  },
  {
    "objectID": "index.html#research-interests",
    "href": "index.html#research-interests",
    "title": "Alexandre Thiéry",
    "section": "",
    "text": "Computational Statistics & Machine Learning\nMonte-Carlo methods\nUncertainty Quantification\nInverse problems"
  },
  {
    "objectID": "index.html#contact",
    "href": "index.html#contact",
    "title": "Alexandre Thiéry",
    "section": "",
    "text": "Office: Building S16, Office #06-113\nEmail: a.h.thiery [at] nus.edu.sg"
  },
  {
    "objectID": "notes/DDPM_deterministic/DDPM_deterministic.html",
    "href": "notes/DDPM_deterministic/DDPM_deterministic.html",
    "title": "From Denoising Diffusion to ODEs",
    "section": "",
    "text": "Consider an empirical data distribution \\(\\pi_{\\mathrm{data}}\\). In order to simulate approximate samples from \\(\\pi_{\\mathrm{data}}\\), Denoising Diffusion Probabilistic Models (DDPM) simulate a forward diffusion process \\(\\{X_t\\}_{[0,T]}\\) on an interval \\([0,T]\\). The diffusion is initialized at the data distribution, i.e. \\(X_0 \\sim \\pi_{\\mathrm{data}}\\), and is chosen so that that the distribution of \\(X_T\\) is very close to a known and tractable reference distribution \\(\\pi_{\\mathrm{ref}}\\), e.g. a Gaussian distribution. Denote by \\(p_t(dx)\\) the marginal distribution at time \\(0 \\leq t \\leq T\\), i.e. \\(\\mathop{\\mathrm{P}}(X_t \\in dx) = p_t(dx)\\). By choosing the forward distribution with simple and tractable transition probabilities, e.g. an Ornstein-Uhlenbeck, it is relatively easy to estimate \\(\\nabla \\log p_t(x)\\) from simulated data: this can be formulated as a simple regression problem. This allows one to simulate the diffusion backward in time and generate approximate samples from \\(\\pi_{\\mathrm{data}}\\). Why this is useful is another question…\nThe fact that the mapping from data-samples at time \\(t=0\\) to (approximate) Gaussian samples at time \\(t=T\\) is stochastic and described by diffusion processes is cumbersome. This would be much more convenient to build a deterministic mapping between the data-distribution \\(\\pi_{\\mathrm{data}}\\) and the Gaussian reference distribution \\(\\pi_{\\mathrm{ref}}\\): this would allows one to associate a likelihood to data samples and to easily “encode”/“decode” data-samples. To so this, one can try to replace diffusion by Ordinary Differential Equations."
  },
  {
    "objectID": "notes/DDPM_deterministic/DDPM_deterministic.html#likelihood-computation",
    "href": "notes/DDPM_deterministic/DDPM_deterministic.html#likelihood-computation",
    "title": "From Denoising Diffusion to ODEs",
    "section": "Likelihood computation",
    "text": "Likelihood computation\nWith the diffusion-ODE trick, we have just seen that it is possible to build a vector fields \\(F[0,T] \\times \\mathbb{R}^d \\to \\mathbb{R}^d\\) such that the forward ODE\n\\[\n\\frac{d}{dt} \\overrightarrow{Y_t} =\nF(t,\\overrightarrow{Y_t})\n\\qquad \\textrm{initialized at} \\qquad\n\\overrightarrow{Y}_0 \\sim \\pi_{\\mathrm{data}}\n\\tag{3}\\]\nand the backward ODE defined as\n\\[\n\\frac{d}{ds} \\overleftarrow{Y_s} =\n-F(T-s,\\overleftarrow{Y_s})\n\\qquad \\textrm{initialized at} \\qquad\n\\overleftarrow{Y}_0 \\sim \\pi_{\\mathrm{ref}}\n\\]\nare such that \\(\\overrightarrow{Y}_T \\approx \\pi_{\\mathrm{ref}}\\) and \\(\\overleftarrow{Y}_T \\approx \\pi_{\\mathrm{data}}\\).\nIn general, consider a vector field \\(F(t,x)\\) and a bunch of particles distributed according to a distribution \\(p_t\\) at time \\(t\\). If each particle follows the vector field for an amount of time \\(\\delta \\ll 1\\), the particles that were in the vicinity of some \\(x \\in \\mathbb{R}^d\\) at time \\(t\\) end up in the vicinity of \\(x + F(x,t) \\, \\delta\\) at time \\(t+\\delta\\). At the same time, a volume element \\(dx\\) around \\(x \\in \\mathbb{R}^d\\) gets stretch by a factor \\(1+\\delta \\, \\mathop{\\mathrm{Tr}}[\\mathop{\\mathrm{\\mathrm{Jac}}}F(x,t)] = 1 + \\delta \\mathop{\\mathrm{div}}F(x,t)\\) while following the vector field \\(F\\), which means that the density of particles at time \\(t+\\delta\\) and around \\(x + F(x,t) \\, \\delta\\) equals \\(p_t(x) / [1 + \\delta \\mathop{\\mathrm{div}}F(x,t)]\\). In other words \\(\\log p_{t+\\delta}(x + F(x,t) \\, \\delta) \\approx \\log p_t(x) - \\delta \\, \\mathop{\\mathrm{div}}F(x,t)\\). This means that if we follows a trajectory of \\(\\tfrac{d}{dt} X_t = F(t,X_t)\\) one gets\n\\[\n\\log p_T(X_T) = \\log p_0(X_0) - \\int_{t=0}^{T} \\mathop{\\mathrm{div}}F(X_t,t) \\, dt.\n\\]\nThat is the Lagrangian description of the density \\(p_t\\) of particles. Indeed, one could directly get this identity by differentiating \\(p_t(X_t)\\) with respect to time while using the continuity Equation 1. When applied to the DDPM, this gives a way to assign likelihood the data samples, namely\n\\[\n\\log \\pi_{\\mathrm{data}}(x) = \\log \\pi_{\\mathrm{ref}}(\\overrightarrow{Y_T}) + \\int_{t=0}^{T} \\mathop{\\mathrm{div}}F(t, \\overrightarrow{Y_t})\\, dt\n\\]\nwhere \\(\\overrightarrow{Y_t}\\) is trajectory of the forward ODE Equation 3 initialized as \\(\\overrightarrow{Y_0} = x\\). Note that in high-dimensional setting, it may be computationally expensive to compute the divergence term \\(\\mathop{\\mathrm{div}}F(t, \\overrightarrow{Y_t})\\) since it typically is \\(d\\) times slower that a gradient computation; for this reason, it is often advocated to use the Hutchinson trace estimator to get an unbiased estimate of it at a much lower computational cost."
  },
  {
    "objectID": "notes/index_notes.html",
    "href": "notes/index_notes.html",
    "title": "\nNotes\n",
    "section": "",
    "text": "Notes\n\nNotes for students, half-baked write-ups for myself, and probably other random maths/stats/ML texts. Certainly full of typos, comments welcome!\n\n\nDenoising Diffusion Probabilistic Models\n\nNoising and Reverse Ornstein-Uhlenbeck\nFrom Denoising Diffusion to ODEs\nReverse diffusions, Score & Tweedie"
  },
  {
    "objectID": "notes/DDPM/DDPM.html",
    "href": "notes/DDPM/DDPM.html",
    "title": "Denoising Diffusion Probabilistic Models (DDPM)",
    "section": "",
    "text": "Setting & Goals\nConsider \\(N\\) samples \\(\\mathcal{D}\\equiv \\{x_i\\}_{i=1}^N\\) in \\(\\mathbb{R}^D\\) from an unknown data distribution \\(\\pi_{\\mathrm{data}}(dx)\\). We would like to build an mechanism that can generate other samples from this data distribution. Implicitly, this means that we will be fitting a statistical model to this finite set of samples and have an algorithmic procedure to generate samples from the fitted probabilistic model. This type of models that directly define a stochastic procedure that generates data are called implicit probabilistic models in the ML literature.\n\n\nOrnstein–Uhlenbeck Noising process\nDDPMs work as follows. Consider a diffusion process \\(\\{ X_t \\}_{t=0}^T\\) that starts from the data distribution \\(p_0(dx) \\equiv \\pi_{\\mathrm{data}}(dx)\\) at time \\(t=0\\). The notation \\(p_t(dx)\\) refers to the marginal distribution of the diffusion at time \\(0 \\leq t \\leq T\\). Assume furthermore that at time \\(t=T\\), the marginal distribution is (very close to) a reference distribution \\(p_T(dx) = \\pi_{\\mathrm{ref}}(dx)\\) that is straightforward to sample from. Typically, \\(\\pi_{\\mathrm{ref}}(dx)\\) is an isotropic Gaussian distribution. This diffusion process is often called the noising process since it transform the data distribution into a reference measure that can be thought of as “pure noise”. It is often chosen as an Ornstein–Uhlenbeck (OU) diffusion,\n\\[\ndX = - \\frac12 X \\, dt + dW.\n\\tag{1}\\]\nThis diffusion is reversible with respect to, and quickly converges to, the reference distribution \\(\\pi_{\\mathrm{ref}} = \\mathcal{N}(0, I)\\) and has the good taste of having simple transition densities: the law of \\(X_{t+s}\\) given that \\(X_t = x_t\\) is the same as \\(e^{-s/2} x_t + \\sqrt{1-e^{-s}} \\, \\mathbf{n}\\), which we write as\n\\[\n\\alpha_s x + \\sigma_s \\, \\mathbf{n}\\qquad \\text{with} \\qquad\n\\left\\{\n\\begin{aligned}\n\\alpha_s &= \\sqrt{1-\\sigma_s^2}\\\\\n\\sigma^2_s &= 1-e^{-s}\n\\end{aligned}\n\\right.\n\\]\nfor isotropic Gaussian noise term \\(\\mathbf{n}\\sim \\pi_{\\mathrm{ref}} = \\mathcal{N}(0,I)\\). We have:\n\\[\nF(s,x,y) \\equiv \\mathop{\\mathrm{P}}(X_{t+s} \\in dy \\, | \\, X_t = x )\n\\; \\propto \\;\n\\exp {\\left\\{ -\\frac{(y - \\alpha_s \\, x)^2}{2 \\, \\sigma^2_s} \\right\\}} .\n\\tag{2}\\]\nwhere the notation \\(F(s,x,y)\\) designates the forward transition from \\(x\\) to \\(y\\) in “\\(s\\)” amount of time. This also means that one can directly generate samples from \\(p_t(dx)\\) by first choosing a data samples \\(x_i\\) from the data distribution \\(p_{\\mathrm{data}} \\equiv p_0\\) and blend it with noise by setting \\(x_i^{(t)} = \\alpha_t \\, x_i + \\sigma_t \\, \\mathbf{n}\\).\n\n\nThe reverse diffusion\nIn order to generate samples from the data distribution, the DDPM strategy consists in sampling from the Gaussian reference measure \\(\\pi_{\\mathrm{ref}}\\) at time \\(t=T\\) and simulate the OU process backward in time. In other words, one would like to simulate from the reverse process \\(\\overleftarrow{X}_t\\) defined as\n\\[\\overleftarrow{X}_s = X_{T-s}.\\]\nIn other words, the reverse process is distributed as \\(\\overleftarrow{X}_0 \\sim \\pi_{\\mathrm{ref}}\\) at time \\(t=0\\) and, crucially, we have that \\(\\overleftarrow{X}_T \\sim \\pi_{\\mathrm{data}}\\). Furthermore, and as explained in this note, the reverse diffusion follows the dynamics\n\\[\nd\\overleftarrow{X}_t = {\\color{red} + }\\frac12 \\overleftarrow{X}_t \\, dt\n\\; {\\color{red} + \\nabla \\log p_{T-t}(\\overleftarrow{X}_t) \\, dt} \\;\n+ dB\n\\tag{3}\\]\nwhere \\(B\\) is another Wiener process. I have used the notation \\(B\\) to emphasize that there is no link between this Wiener process and the one used to simulate the forward process. Note that if the initial data distribution \\(p_0 \\equiv \\pi_{\\mathrm{data}}\\) were equal to the reference measure \\(\\pi_{\\mathrm{ref}}\\), i.e. \\(p_0 = p_T = \\pi_{\\mathrm{ref}}\\) then it is easy to see that the reverse diffusion would have exactly teh same dynamics as the forward diffusion. In order to simulate the reverse diffusion, one needs to be able to estimate the new term \\({\\color{red}\\nabla \\log p_{T-t}(x)}\\) called the score. If one can estimate the score, it is straightforward to simulate the reverse process \\(\\overleftarrow{X}_t\\) all the way to \\(t=T\\) and obtain samples from the data distribution.\n\n\nDenoising to estimating the score\nIn practice, the score is unknown and one has to build an approximation of it\n\\[\\mathcal{S}(t,x) \\; \\approx \\; \\nabla_x \\log p_t(x).\\]\nThe approximate score \\(\\mathcal{S}(t,x)\\) is often parametrized by a neural network. Since the forward transitions are available and\n\\[\n\\log p_t(x) \\; = \\; \\log \\int \\; F(t, x_0, x)\\; \\pi_{\\mathrm{data}}(d x_0)\n\\]\nthe analytical expression of \\(F(t, x_0, x)\\) given in Equation 2 readily gives that\n\\[\n\\nabla_x \\log p_t(x) \\; = \\; -\\frac{x - \\alpha_t \\, \\widehat{x}_0(x,t)}{\\sigma_t^2}\n\\tag{4}\\]\nwhere \\(\\widehat{x}_0(x,t)\\) is a “denoising” estimate of the initial position \\(x_0\\) given a noisy estimate \\(X_t=x\\) at time \\(t\\),\n\\[\n\\widehat{x}_0(x,t) \\; = \\; \\mathop{\\mathrm{E}}[X_0  \\; \\mid \\; X_t = x].\n\\]\nFor simplifying notation, I will often write \\(\\widehat{x}_0(x_t, t)\\) as \\(\\widehat{x}_0(x_t)\\) when it is clear that \\(x_t\\) is a sample obtained at time \\(0 \\leq t \\leq T\\). Equation 4 means that to estimate the score, one only needs to train a denoising function\n\\[\n\\widehat{x}_0(\\cdots): [0,T] \\times \\mathbb{R}^d \\to \\mathbb{R}^d.\n\\]\nIt is a simple regression problem: take a bunch of pairs \\((X_0, X_t)\\) that can be generated as\n\\[\nX_0 \\sim \\pi_{\\mathrm{data}}\n\\qquad \\textrm{and} \\qquad\nX_t = \\alpha_t X_0 + \\sigma_t \\, \\mathbf{n}\n\\]\nwith \\(\\mathbf{n}\\sim \\mathcal{N}(0,I)\\) and minimize the Mean Squared Error (MSE) loss, i.e.\n\\[\n\\mathop{\\mathrm{E}}\\|X_0 - \\widehat{x}_0(t, X_t)\\|^2,\n\\]\nwith stochastic gradient descent or any other stochastic optimization procedure. The score is then defined as\n\\[\n\\mathcal{S}(t,x) \\; = \\; -\\frac{x - \\alpha_t \\, \\widehat{x}_0(t,x)}{\\sigma^2_t}.\n\\]\n\n\nDenoiser: practical parametrization and training\nIn practice, it may not be efficient, or stable, to try to directly parametrize the denoiser \\(\\widehat{x}_0(\\cdots)\\) with a neural network and simply descend the loss\n\\[\n\\mathop{\\mathrm{E}}\\|X_0 - \\widehat{x}_0(t, X_t)\\|^2.\n\\]\nFor example, for \\(t \\approx 0\\), we have that \\(\\widehat{x}_0(t,X_t) \\approx X_t \\approx X_0\\) so that it is very easy to reconstruct \\(X_0\\) from \\(X_t\\). On the contrary, for large \\(t\\), there is almost no information contained within \\(X_t\\) to reconstruct \\(X_0\\). This means that the typical value of the loss depends widely on \\(t\\), which makes it difficult to optimize: with this parametrization, since large values of the loss will be typically concentrated to large values of \\(t\\), the denoiser will not be accurate for \\(t \\approx 0\\), leading to sub-optimal results. Since \\(X_t = \\alpha_t \\, X_0 + \\sigma_t \\, \\mathbf{n}\\), one can defined the Signal-to-Noise-Ratio as\n\\[\\mathrm{SNR}(t) = \\frac{\\alpha_t}{\\sigma_t}\\]\nand, in order to normalize by the reconstruction difficulty, it makes more sense to train a denoiser by minimizing the loss:\n\\[\n\\mathop{\\mathrm{E}} {\\left[  \\mathrm{SNR}^2(t) \\times \\|X_0 - \\widehat{x}_0(t, X_t)\\|^2  \\right]} .\n\\]\nIt turns out that it is entirely equivalent to minimizing the loss\n\\[\n\\mathop{\\mathrm{E}} {\\left[  \\| \\mathbf{n}- \\widehat{\\mathbf{n}}(t, X_t)\\|^2  \\right]} .\n\\]\nwhere \\(X_t = \\alpha_t \\, X_0 + \\sigma_t \\, \\mathbf{n}\\) while the denoiser \\(\\widehat{x}_0(\\ldots)\\) and noise estimator \\(\\widehat{\\mathbf{n}}(\\ldots)\\) are parametrized so that\n\\[\nX_t = \\alpha_t \\, \\widehat{x}_0(t, X_t) + \\sigma_t \\, \\widehat{\\mathbf{n}}(t,X_t).\n\\]\nThat is one of the reasons why most of the papers on DDPM are parametrizing the denoiser \\(\\widehat{x}_0(\\ldots)\\) by building instead a “noise estimator” \\(\\widehat{\\mathbf{n}}(\\ldots)\\) with a neural network and setting\n\\[\n\\widehat{x}_0(t,X_t) = \\frac{X_t - \\sigma_t \\, \\widehat{\\mathbf{n}}(t,X_T)}{\\alpha_t}.\n\\]\nSince \\(\\alpha_t \\to 1\\) and \\(\\sigma_t \\to 0\\) for \\(t \\ll 1\\), this also implicitly ensures that \\(\\widehat{x}_0(t,X_t) \\approx X_t\\) for \\(t \\ll 1\\), as required.\n\n\n\nThe “denoising” diffusion\nOnce the denoiser \\(\\widehat{x}_0(\\ldots)\\) has been trained, the reverse diffusion defined \\(\\overleftarrow{X}_s = X_{T-s}\\) as to be simulated. Plugging Equation 4 back in the expression of the dynamics of the reverse diffusion shows that\n\\[\nd\\overleftarrow{X}_s =\n-\\frac12 \\, \\frac{1}{\\tanh((T-s)/2)} \\,\n{\\left(  \\overleftarrow{X}_s - \\frac{\\widehat{x}_0(\\overleftarrow{X}_s)}{\\cosh((T-s)/2)}  \\right)}\n\\; + \\;\ndB\n\\tag{5}\\]\nThis dynamics is intuitive: as \\(s \\to T\\) we have \\(\\cosh((T-s)/2) \\to 1\\) and \\(\\varepsilon^2 \\equiv \\tanh((T-s)/2) \\sim (T-s)/2 \\to 0\\) so that the dynamics is similar to\n\\[\nd\\overleftarrow{X}_s =\n-\\frac12 \\, \\frac{1}{\\varepsilon^2} \\,\n{\\left(  \\overleftarrow{X}_s - \\widehat{x}_0 \\right)}\n\\; + \\;\ndB\n\\]\nwhich is OU process that converges quickly, i.e. on time-scale of order \\(\\mathcal{O}(\\varepsilon^2)\\), towards a Gaussian distribution with mean \\(\\widehat{x}_0\\) (i.e. the denoised estimate) and variance \\(\\varepsilon^2\\).\nTo discretize the reverse dynamics Equation 5 on a small interval \\([\\overline{s}, \\overline{s}+\\delta]\\), one can for example consider the slightly simplified (linear) dynamics\n\\[\nd\\overleftarrow{X}_s =\n-\\frac12 \\, \\frac{1}{\\tanh((T-s)/2)} \\,\n{\\left(  \\overleftarrow{X}_s - \\mu \\right)} .\n\\; + \\;\ndB\n\\]\nHere, \\(\\mu = \\widehat{x}_0(\\overleftarrow{X}_{\\overline{s}}) / \\cosh((T-\\overline{s})/2)\\) with \\(\\overleftarrow{X}_{\\overline{s}} = \\overleftarrow{x}_{\\overline{s}}\\). Algebra gives that, conditioned upon \\(\\overleftarrow{X}_{\\overline{s}} = \\overleftarrow{x}_{\\overline{s}}\\), we have\n\\[\n\\left\\{\n\\begin{aligned}\n\\mathop{\\mathrm{E}}[ \\overleftarrow{X}_{\\overline{s} + \\delta} ]\n\\quad &= \\quad \\mu + \\lambda \\, (\\overleftarrow{x}_{\\overline{s}} - \\mu)\\\\\n\\mathop{\\mathrm{Var}}[ \\overleftarrow{X}_{\\overline{s} + \\delta} ]\n\\quad &= \\quad\n\\tanh {\\left( \\frac{T-\\overline{s}-\\delta}{2} \\right)}  \\, (1-\\lambda^2)\n\\end{aligned}\n\\right.\n\\]\nwhere the coefficient \\(0&lt;\\lambda&lt;1\\) is given by\n\\[\n\\lambda = \\frac{\\sinh(T-\\overline{s}-\\delta)}{\\sinh(T-\\overline{s})}.\n\\]\nThis discretization is more stable and efficient than a naive Euler-Maruyama approach since the drift term can get large as \\(s \\to T\\). WIth the above discretization, one can easily simulate the reverse diffusion on \\([0,T]\\) and generate approximate samples from \\(\\pi_{\\mathrm{data}}\\).\nIn the animation below, the method described in these notes was used. This very small example trains in less than a minute on an old laptop without a GPU. The noise estimator was parametrized with an MLP with \\(\\mathrm{elu}(\\ldots)\\) non-linearity and two hidden-layers with size \\(H=128\\). It was very useful to add a few Fourier features as input of the network, I could not make this work properly without.\n\n\nVideo\n\n\nThe literature on DDPM is enormous and still growing!"
  },
  {
    "objectID": "teaching/teaching.html",
    "href": "teaching/teaching.html",
    "title": "Alexandre Thiéry",
    "section": "",
    "text": "DSA4212: Large Scale optimization, NUS (2017 – 2022)\nYSC4236: Optimization for Large Scale Inference, Yale-NUS, (2022)\nYSC3252: Computational Statistics, Yale-NUS, (2022)\nDSA5843: Learning from Data: Neural Networks, NUS (2020–2021)\nST3233: Applied Times Series, NUS, (2016, 2019, 2021)\nST4240: Data Mining, NUS, (2014–2017)\nST4231: Computationally Intensive Statistics, NUS (2014–2015)\nMultivariable Calculus II, Chennai (CMI), (2018)"
  },
  {
    "objectID": "teaching/teaching.html#semester-long-courses",
    "href": "teaching/teaching.html#semester-long-courses",
    "title": "Alexandre Thiéry",
    "section": "",
    "text": "DSA4212: Large Scale optimization, NUS (2017 – 2022)\nYSC4236: Optimization for Large Scale Inference, Yale-NUS, (2022)\nYSC3252: Computational Statistics, Yale-NUS, (2022)\nDSA5843: Learning from Data: Neural Networks, NUS (2020–2021)\nST3233: Applied Times Series, NUS, (2016, 2019, 2021)\nST4240: Data Mining, NUS, (2014–2017)\nST4231: Computationally Intensive Statistics, NUS (2014–2015)\nMultivariable Calculus II, Chennai (CMI), (2018)"
  },
  {
    "objectID": "teaching/teaching.html#lecture-series",
    "href": "teaching/teaching.html#lecture-series",
    "title": "Alexandre Thiéry",
    "section": "Lecture Series:",
    "text": "Lecture Series:\n\nSummer school on Bayesian statistics (5h Lecture), VIASM July 2023"
  },
  {
    "objectID": "people/index_people.html",
    "href": "people/index_people.html",
    "title": "Research team",
    "section": "",
    "text": "Woon Hao Xuan PhD (2023–Now): Uncertainty Quantification for High-Dimensional dynamical systems."
  },
  {
    "objectID": "people/index_people.html#phdpostdoc-co-supervision",
    "href": "people/index_people.html#phdpostdoc-co-supervision",
    "title": "Research team",
    "section": "",
    "text": "Woon Hao Xuan PhD (2023–Now): Uncertainty Quantification for High-Dimensional dynamical systems."
  },
  {
    "objectID": "people/index_people.html#alumni",
    "href": "people/index_people.html#alumni",
    "title": "Research team",
    "section": "Alumni",
    "text": "Alumni\n\nChristopher Hendra PhD (2019-2022): Genomics, Nanopore sequencing – co-supervised by Jonathan Göke (GIS). Chris is now a Senior Scientist at MSD.\nKhai Xiang Au PhD (2019-2023): PDE constrained Bayesian inverse problems, uncertainty quanification, variational inference. Khai is now working as a data scientist at American Express.\nRahul Rahaman PhD(2018-2022): Bayesian inference, Uncertainty Quantification, Deep-Learning. Rahul is now an Applied Research Scientist at Amazon.\nAtin Ghosh PhD (2017-2021): Deep Learning for Glaucoma Understanding, representation learning, generative models, semi-supervised learning. Atin is now an Applied Research Scientist at Amazon.\nSe-In Jang Research Fellow (2019-2021): Computer vision and application to ophthalmology. Se-In is now a research fellow in the Center for Advanced Medical Computing and Analysis and the Gordon Center for Medical Imaging, Massachusetts General Hospital (MGH) and Harvard Medical School.\nAxel Finke Research Fellow (2017-2020): Sequential Monte Carlo, MCMC, algorithms for high-dimensional problems; applications in finance, economics, ecology and molecular biology. Axel is now an assistant professor at Loughborough University (UK).\nZuozhu Liu Research Fellow (2019-2020): Bayesian inference, deep generative models, 3D vision and medical applications. Zuozhu is now Assistant Professor at the Zhejiang University-University of Illinois at Urbana-Champaign Institute.\nMatt Graham Research Fellow (2017-2020): Approximate inference methods, MCMC, approximate Bayesian computation, numerical simulation. Matt is now a research data scientist in the Advanced Research Computing Centre at University College London.\nWillem van den Boom Research Fellow (2018-2019): Willem is now a Senior Research Fellow in the Division of Biomedical Data Science at the Yong Loo Lin School of Medicine of the National University of Singapore.\nKhai Sing Chin Research Associate (2017-2018): Khai Sing is now working in the finance industry.\nDeborshee Sen PhD (NUS, 2014-2017). Winner of the 2017 DSAP NUS best researcher award. After a postdoc at Duke University and a position as an assistant Professor at Bath University, Deborshee now works as a Research Scientist at Amazon.\nDaniel Paulin Research Fellow (NUS, 2014-2015). Daniel is now an Assistant Professor at the School of Mathematics at the University of Edinburgh.\nEge Muzaffer PhD (NUS, 2016): Bayesian inverse problems and Sequential Monte Carlo. Ege is now a Machine Learning EngineerMachine Learning Engineer Ubisoft RedLynx"
  },
  {
    "objectID": "people/index_people.html#msc",
    "href": "people/index_people.html#msc",
    "title": "Research team",
    "section": "MSc",
    "text": "MSc\n\nQuang Huy Nguyen MSc (2018-2019): representation learning, robust models for image segmentation.\nAugustin Hoff (NUS, 2016-2017). Deep Neural Networks and Features Extraction. Augustin is now a Senior Data Scientist at MAIF.\nMajdi Rabia (NUS, 2016-2017). Numerical Method for Backward-Stochastic-Differential-Equations. Majdi is Co-founder and CTO @Fairphonic.\nBenjamin Scellier (NUS, 2015). Deep Learning. After his MSc at NUS, Benjamin joined Yoshua Bengio’s Group as a PhD. He is now a principal research scientist at Rain"
  },
  {
    "objectID": "notes/reverse_and_tweedie/reverse_and_tweedie.html",
    "href": "notes/reverse_and_tweedie/reverse_and_tweedie.html",
    "title": "Reverse diffusions, Score & Tweedie",
    "section": "",
    "text": "Video\n\n\nImagine a scalar diffusion process \\(\\{X_t\\}_{t=0}^T\\) defined on the interval \\([0,T]\\),\n\\[dX = \\mu(X) \\, dt + \\sigma \\, dW\\]\nwhere \\(\\mu(X)\\) is the drift term, \\(\\sigma\\) is the diffusion coefficient, and \\(dW\\) is a Wiener process. Denote the distribution of this process at time \\(t\\) (\\(0 \\leq t \\leq T\\)) as \\(p_t(dx)\\) with an initial distribution of \\(p_0(dx)\\). Now, what happens if we reverse time and examine the process backward? In other words, consider the time-reversed process \\(\\overleftarrow{X}\\) defined as\n\\[\\overleftarrow{X}_s = X_{T-s}.\\]\nIntuitively, the process \\(\\overleftarrow{X}\\) is also a diffusion on the interval \\([0, T]\\), but with an initial distribution \\(\\overleftarrow{X}_0 \\sim p_T(dx)\\). To gain intuition, consider an Euler discretization of the forward process:\n\\[X_{t+\\delta} = X_{t} + \\mu(X_t)\\, \\delta + \\sigma \\, \\sqrt{\\delta} \\, \\mathbf{n} \\tag{1}\\]\nwhere \\(\\mathbf{n}\\sim \\mathcal{N}(0,1)\\) represents a noise term independent from \\(X_{t}\\), and \\(\\delta \\ll 1\\) is a time increment. Re-arranging terms and making the approximation \\(\\mu(X_t) \\approx \\mu(X_{t+\\delta})\\) gives that\n\\[X_{t} \\approx X_{t+\\delta} - \\mu(X_{t+\\delta})\\, \\delta + \\sigma \\, \\sqrt{\\delta} \\, (-\\mathbf{n}). \\tag{2}\\]\nThis seems to suggest that the time-reversed process follows the dynamics \\(d\\overleftarrow{X} = -\\mu(\\overleftarrow{X}) \\, dt + \\sigma \\, dW\\) started from \\(\\overleftarrow{X}_0 \\sim p_T(dx)\\). However, this conclusion is incorrect because this would suggest that the time-reversed of a standard Brownian motion (where \\(\\mu(x) \\equiv 0\\)) starting at zero is also a Brownian motion starting at \\(p_T(dx) = \\mathcal{N}(0,T)\\), which is clearly not the case. The flaw in this argument lies in assuming that the noise term \\(Z\\) is independent of \\(X_{t+\\delta}\\), which is not true, rendering the Euler discretization argument invalid.\nDeriving the dynamics of the backward process in a rigorous manner is not straightforward (Anderson 1982) (Haussmann and Pardoux 1986). What follows is a heuristic derivation that proceeds by estimating the mean and variance of \\(X_{t}\\) given \\(X_{t+\\delta} = x_{t+\\delta}\\), assuming \\(\\delta \\ll 1\\). Here, \\(x_{t+\\delta}\\) is treated as a fixed and constant value, and we are only interested in the conditional distribution of \\(X_t\\) given \\(x_{t+\\delta}\\). Bayes’ law gives\n\\[\\mathbb{P}(X_t \\in dx | x_{t+\\delta}) \\propto p_t(x) \\, \\exp\\left\\{ -\\frac{\\left( x_{t+\\delta} - [x + \\mu(x) \\, \\delta] \\right)^2}{2 \\sigma^2 \\, \\delta} \\right\\},\\]\nwhere the exponential term corresponds to the transition of the forward diffusion for \\(\\delta \\ll 1\\). Using the 1st order approximation\n\\[p_t(x) \\approx p_t(x_{t+\\delta}) \\,\\exp\\left( \\langle \\nabla \\log p_t(x_{t+\\delta}), (x-x_{t+\\delta})\\rangle\\right),\\]\neliminating multiplicative constants and higher-order error terms, we obtain:\n\\[\\mathbb{P}(X_t \\in dx | x_{t+\\delta})\n\\propto\n\\exp\\left\\{ -\\frac{\\left( x - [x_{t+\\delta} - \\mu(x_{t+\\delta}) \\delta\n+ {\\color{red} \\sigma^2 \\, \\nabla \\log p_t(x_{t+\\delta}) \\, \\delta} ] \\right)^2}{2 \\sigma^2 \\, \\delta} \\right\\}.\\]\nFor \\(\\delta \\ll 1\\), this is transition of the reverse diffusion\n\\[\nd\\overleftarrow{X}_t = -\\mu(\\overleftarrow{X}_t) \\, dt \\; + {\\color{red} \\sigma^2 \\, \\nabla \\log p_{T-t}(\\overleftarrow{X}_t) \\, dt} \\; + \\; \\sigma \\, dB.\n\\]\nThe notation \\(B\\) is used to emphasize that this Brownian motion is distinct from the one used in the forward diffusion. The additional drift term, denoted as \\({\\color{red} \\sigma^2 \\, \\nabla \\log p_t(\\overleftarrow{X})}\\), is intuitive: it pushes the reverse diffusion toward regions where the forward diffusion spent a significant amount of time, i.e., where \\(p_t(dx)\\) is large. The popular “denoising diffusion models” (Ho, Jain, and Abbeel 2020) can be seen as discretizations of this backward process, employing various techniques to estimate the additional drift term from data."
  },
  {
    "objectID": "notes/reverse_and_tweedie/reverse_and_tweedie.html#reversing-a-diffusion",
    "href": "notes/reverse_and_tweedie/reverse_and_tweedie.html#reversing-a-diffusion",
    "title": "Reverse diffusions, Score & Tweedie",
    "section": "",
    "text": "Video\n\n\nImagine a scalar diffusion process \\(\\{X_t\\}_{t=0}^T\\) defined on the interval \\([0,T]\\),\n\\[dX = \\mu(X) \\, dt + \\sigma \\, dW\\]\nwhere \\(\\mu(X)\\) is the drift term, \\(\\sigma\\) is the diffusion coefficient, and \\(dW\\) is a Wiener process. Denote the distribution of this process at time \\(t\\) (\\(0 \\leq t \\leq T\\)) as \\(p_t(dx)\\) with an initial distribution of \\(p_0(dx)\\). Now, what happens if we reverse time and examine the process backward? In other words, consider the time-reversed process \\(\\overleftarrow{X}\\) defined as\n\\[\\overleftarrow{X}_s = X_{T-s}.\\]\nIntuitively, the process \\(\\overleftarrow{X}\\) is also a diffusion on the interval \\([0, T]\\), but with an initial distribution \\(\\overleftarrow{X}_0 \\sim p_T(dx)\\). To gain intuition, consider an Euler discretization of the forward process:\n\\[X_{t+\\delta} = X_{t} + \\mu(X_t)\\, \\delta + \\sigma \\, \\sqrt{\\delta} \\, \\mathbf{n} \\tag{1}\\]\nwhere \\(\\mathbf{n}\\sim \\mathcal{N}(0,1)\\) represents a noise term independent from \\(X_{t}\\), and \\(\\delta \\ll 1\\) is a time increment. Re-arranging terms and making the approximation \\(\\mu(X_t) \\approx \\mu(X_{t+\\delta})\\) gives that\n\\[X_{t} \\approx X_{t+\\delta} - \\mu(X_{t+\\delta})\\, \\delta + \\sigma \\, \\sqrt{\\delta} \\, (-\\mathbf{n}). \\tag{2}\\]\nThis seems to suggest that the time-reversed process follows the dynamics \\(d\\overleftarrow{X} = -\\mu(\\overleftarrow{X}) \\, dt + \\sigma \\, dW\\) started from \\(\\overleftarrow{X}_0 \\sim p_T(dx)\\). However, this conclusion is incorrect because this would suggest that the time-reversed of a standard Brownian motion (where \\(\\mu(x) \\equiv 0\\)) starting at zero is also a Brownian motion starting at \\(p_T(dx) = \\mathcal{N}(0,T)\\), which is clearly not the case. The flaw in this argument lies in assuming that the noise term \\(Z\\) is independent of \\(X_{t+\\delta}\\), which is not true, rendering the Euler discretization argument invalid.\nDeriving the dynamics of the backward process in a rigorous manner is not straightforward (Anderson 1982) (Haussmann and Pardoux 1986). What follows is a heuristic derivation that proceeds by estimating the mean and variance of \\(X_{t}\\) given \\(X_{t+\\delta} = x_{t+\\delta}\\), assuming \\(\\delta \\ll 1\\). Here, \\(x_{t+\\delta}\\) is treated as a fixed and constant value, and we are only interested in the conditional distribution of \\(X_t\\) given \\(x_{t+\\delta}\\). Bayes’ law gives\n\\[\\mathbb{P}(X_t \\in dx | x_{t+\\delta}) \\propto p_t(x) \\, \\exp\\left\\{ -\\frac{\\left( x_{t+\\delta} - [x + \\mu(x) \\, \\delta] \\right)^2}{2 \\sigma^2 \\, \\delta} \\right\\},\\]\nwhere the exponential term corresponds to the transition of the forward diffusion for \\(\\delta \\ll 1\\). Using the 1st order approximation\n\\[p_t(x) \\approx p_t(x_{t+\\delta}) \\,\\exp\\left( \\langle \\nabla \\log p_t(x_{t+\\delta}), (x-x_{t+\\delta})\\rangle\\right),\\]\neliminating multiplicative constants and higher-order error terms, we obtain:\n\\[\\mathbb{P}(X_t \\in dx | x_{t+\\delta})\n\\propto\n\\exp\\left\\{ -\\frac{\\left( x - [x_{t+\\delta} - \\mu(x_{t+\\delta}) \\delta\n+ {\\color{red} \\sigma^2 \\, \\nabla \\log p_t(x_{t+\\delta}) \\, \\delta} ] \\right)^2}{2 \\sigma^2 \\, \\delta} \\right\\}.\\]\nFor \\(\\delta \\ll 1\\), this is transition of the reverse diffusion\n\\[\nd\\overleftarrow{X}_t = -\\mu(\\overleftarrow{X}_t) \\, dt \\; + {\\color{red} \\sigma^2 \\, \\nabla \\log p_{T-t}(\\overleftarrow{X}_t) \\, dt} \\; + \\; \\sigma \\, dB.\n\\]\nThe notation \\(B\\) is used to emphasize that this Brownian motion is distinct from the one used in the forward diffusion. The additional drift term, denoted as \\({\\color{red} \\sigma^2 \\, \\nabla \\log p_t(\\overleftarrow{X})}\\), is intuitive: it pushes the reverse diffusion toward regions where the forward diffusion spent a significant amount of time, i.e., where \\(p_t(dx)\\) is large. The popular “denoising diffusion models” (Ho, Jain, and Abbeel 2020) can be seen as discretizations of this backward process, employing various techniques to estimate the additional drift term from data."
  },
  {
    "objectID": "notes/reverse_and_tweedie/reverse_and_tweedie.html#denoising-score-matching-tweedie-formula",
    "href": "notes/reverse_and_tweedie/reverse_and_tweedie.html#denoising-score-matching-tweedie-formula",
    "title": "Reverse diffusions, Score & Tweedie",
    "section": "Denoising Score Matching & Tweedie formula",
    "text": "Denoising Score Matching & Tweedie formula\n\n\n\n\nMaurice Tweedie (1919–1996)\n\n\n\nThe previous section shows that a quantity often referred to as the “score” in machine learning (ML) literature, i.e. \\(\\mathcal{S}_t(x) \\equiv \\nabla_x \\log p_t(x)\\), naturally arises when a diffusion process runs backward in time. Interestingly, it is worth noting that since the beginning of times statisticians have been using the term “score” to refer to the other derivative, i.e. the derivative with respect to a model’s parameter, which is a completely different object!\nConsider a Brownian diffusion process \\(dX = \\sigma \\, dW\\) initiated from a distribution \\(\\mu(dx) = p_0(dx)\\). If this process is ran forward for a duration \\(\\delta&gt;0\\), we have:\n\\[X_{\\delta} = X_0 + \\mathcal{N}(0, \\sigma^2 \\, \\delta)\\]\nwhere \\(X_0 \\sim \\mu(dx)\\). Now, focusing on a specific sample \\(y = X_{\\delta}\\), the backward dynamics \\(d\\overleftarrow{X} = \\sigma^2 \\, \\nabla \\log p_t(\\overleftarrow{X}) , dt + \\sigma \\, dB\\) suggests that for sufficiently small \\(\\delta\\), the following approximation holds:\n\\[\n\\mathbb{E}[X_0 \\, | X_{\\delta} = y] \\; { \\color{\\red} \\approx} \\; y + \\nabla \\log p_{\\delta}(y) \\, \\sigma^2 \\delta.\n\\tag{3}\\]\nMaybe surprisingly, in the case of Brownian dynamics (no drift), this relationship holds exactly, even for arbitrarily large time increments \\(\\delta&gt;0\\). This observation attributed in (Efron 2011) to Maurice Tweedie (1919–1996) has a straightforward proof. Specifically, if \\(X \\sim \\mu(dx)\\), then \\(Y = X + \\mathcal{N}(0, \\Gamma^2)\\) has a density given by:\n\\[\np_Y(dy) = \\int \\mu(x) \\, \\rho_{\\Gamma}(y-x) \\, dx\n\\]\nwhere \\(\\rho_{\\Gamma}(z) \\propto \\exp[-z^2/(2 \\Gamma^2)]\\) is a centred Gaussian with variance \\(\\Gamma^2\\). It follows that\n\\[\n\\frac{ \\mathbb{E}[X \\, | Y = y]-y}{\\Gamma^2} = \\frac{ \\int \\left( \\frac {x-y }{\\Gamma^2} \\right)\\, \\mu(x) \\, \\rho_{\\Gamma}(y-x) \\, dx }{\\int \\mu(x) \\, \\rho_{\\Gamma}(y-x) \\, dx}\n=\n\\nabla_y \\log \\left\\{ \\int \\mu(x) \\, \\rho_{\\Gamma}(y-x) \\, dx \\right\\}\n\\]\nsince \\(\\nabla_y \\rho_{\\Gamma}(y-x) = (x-y)/\\Gamma^2\\). This leads to Tweedie’s formula:\n\\[\n\\mathbb{E}[X \\, | Y = y] \\; {\\color{red} =} \\; y + \\Gamma^2 \\, \\nabla \\log p_Y(y),\n\\]\nwhich is exactly the same as Equation 3 but with an equality sign: no approximation needed! Interestingly, this is what Machine-Learners often refer to as “denoising score matching” (Vincent 2011): if we have access to a large number of samples \\((X_i,Y_i)\\), where \\(X_i \\sim \\mu(dx)\\) and \\(Y_i = X_i + \\mathcal{N}(0, \\Gamma^2)\\), and fit a regression model \\(F_{\\theta}\\) by minimizing the mean-squared error \\(\\theta \\mapsto \\mathbb{E} \\|X - F_{\\theta}(Y)\\|^2\\), then Tweedie formula shows that in the limit of infinite samples and with sufficient flexibility in the regression model \\(F_{\\theta_\\star}(y) = y + \\Gamma^2 \\nabla \\log p_Y(y)\\). This allows one to estimate \\(\\nabla \\log p_Y\\) from data, which is often a good approximation of \\(\\nabla \\log \\mu\\) if the variance \\(\\Gamma^2\\) of the added noise is not too large. Indeed, things can go bad if \\(\\Gamma^2\\) is very small and the number of training data is not large, no free lunch!"
  }
]